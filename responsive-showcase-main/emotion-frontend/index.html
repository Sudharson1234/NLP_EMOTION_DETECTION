<!DOCTYPE html>
<html lang="en">
<head>
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>

  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0"/>
  <title>EmotiSense - Real-Time Emotion Detection</title>

  <style>
    * {
      margin: 0;
      padding: 0;
      box-sizing: border-box;
      scroll-behavior: smooth;
      font-family: "Segoe UI", Arial, sans-serif;
    }

    body {
      background: radial-gradient(circle at top, #0b1b2f 0%, #040914 70%);
      color: white;
      overflow-x: hidden;
    }

    /* Animated dots background */
    .bg-dots {
      position: fixed;
      inset: 0;
      z-index: -2;
      opacity: 0.35;
      background-image:
        radial-gradient(#1ae0ff 1px, transparent 1px),
        radial-gradient(#00aaff 1px, transparent 1px);
      background-size: 80px 80px, 120px 120px;
      background-position: 0 0, 40px 60px;
      filter: blur(0.2px);
      animation: moveDots 12s linear infinite;
    }

    @keyframes moveDots {
      from { transform: translateY(0px); }
      to { transform: translateY(-40px); }
    }

    /* Navbar */
    header {
      position: sticky;
      top: 0;
      z-index: 1000;
      background: rgba(5, 10, 20, 0.65);
      backdrop-filter: blur(12px);
      border-bottom: 1px solid rgba(255,255,255,0.08);
    }

    .nav {
      max-width: 1200px;
      margin: auto;
      padding: 16px 22px;
      display: flex;
      align-items: center;
      justify-content: space-between;
    }

    .brand {
      display: flex;
      gap: 10px;
      align-items: center;
      font-weight: 700;
      font-size: 22px;
      color: #33d6ff;
      letter-spacing: 0.5px;
    }

    .brand-logo {
      width: 36px;
      height: 36px;
      border-radius: 10px;
      background: linear-gradient(135deg, #00eaff, #0066ff);
      display: grid;
      place-items: center;
      box-shadow: 0 0 20px rgba(0, 234, 255, 0.35);
    }

    .brand-logo span {
      font-weight: 900;
      color: #001427;
    }

    nav ul {
      list-style: none;
      display: flex;
      gap: 22px;
      align-items: center;
    }

    nav a {
      text-decoration: none;
      color: rgba(255,255,255,0.75);
      font-size: 14.5px;
      transition: 0.2s ease;
    }

    nav a:hover {
      color: #33d6ff;
    }

    .btn-primary {
      padding: 10px 16px;
      border-radius: 12px;
      background: #33d6ff;
      border: none;
      cursor: pointer;
      font-weight: 700;
      color: #00111f;
      transition: 0.2s ease;
      box-shadow: 0 0 22px rgba(51, 214, 255, 0.25);
    }

    .btn-primary:hover {
      transform: translateY(-1px);
    }

    /* Section base */
    section {
      max-width: 1200px;
      margin: auto;
      padding: 60px 22px;
    }

    /* Hero */
    .hero {
      padding-top: 70px;
      text-align: center;
    }

    .pill {
      display: inline-flex;
      align-items: center;
      gap: 10px;
      padding: 10px 14px;
      border-radius: 999px;
      border: 1px solid rgba(51, 214, 255, 0.25);
      background: rgba(0, 234, 255, 0.07);
      color: rgba(255,255,255,0.9);
      font-size: 13.5px;
      margin-bottom: 22px;
    }

    .hero h1 {
      font-size: 54px;
      line-height: 1.08;
      font-weight: 900;
      letter-spacing: 1px;
    }

    .hero h1 .accent {
      background: linear-gradient(90deg, #33d6ff, #3b82f6);
      -webkit-background-clip: text;
      background-clip: text;
      color: transparent;
    }

    .hero p {
      max-width: 760px;
      margin: 22px auto 34px auto;
      color: rgba(255,255,255,0.72);
      font-size: 16px;
      line-height: 1.7;
    }

    .hero-actions {
      display: flex;
      justify-content: center;
      gap: 16px;
      flex-wrap: wrap;
      margin-bottom: 44px;
    }

    .btn-secondary {
      padding: 10px 16px;
      border-radius: 12px;
      background: rgba(255,255,255,0.05);
      border: 1px solid rgba(255,255,255,0.12);
      cursor: pointer;
      font-weight: 700;
      color: white;
      transition: 0.2s ease;
    }

    .btn-secondary:hover {
      border-color: rgba(51, 214, 255, 0.35);
      color: #33d6ff;
    }

    .stats {
      display: grid;
      grid-template-columns: repeat(4, 1fr);
      gap: 18px;
      margin-top: 40px;
    }

    .stat-card {
      border-radius: 18px;
      padding: 18px;
      border: 1px solid rgba(255,255,255,0.08);
      background: rgba(255,255,255,0.04);
      text-align: center;
    }

    .stat-card h2 {
      font-size: 30px;
      color: #33d6ff;
      margin-bottom: 6px;
      font-weight: 900;
    }

    .stat-card p {
      color: rgba(255,255,255,0.6);
      font-size: 13.5px;
    }

    /* Section title */
    .section-title {
      text-align: center;
      margin-bottom: 34px;
    }

    .section-title h2 {
      font-size: 44px;
      font-weight: 900;
    }

    .section-title h2 span {
      color: #33d6ff;
    }

    .section-title p {
      margin-top: 12px;
      max-width: 720px;
      margin-left: auto;
      margin-right: auto;
      color: rgba(255,255,255,0.68);
      line-height: 1.6;
    }

    /* Cards grid */
    .grid3 {
      display: grid;
      grid-template-columns: repeat(3, 1fr);
      gap: 20px;
    }

    .card {
      border-radius: 22px;
      padding: 22px;
      border: 1px solid rgba(255,255,255,0.08);
      background: rgba(255,255,255,0.035);
      transition: 0.2s ease;
    }

    .card:hover {
      transform: translateY(-3px);
      border-color: rgba(51, 214, 255, 0.35);
      box-shadow: 0 0 30px rgba(51, 214, 255, 0.12);
    }

    .icon-box {
      width: 52px;
      height: 52px;
      border-radius: 16px;
      background: rgba(51, 214, 255, 0.14);
      display: grid;
      place-items: center;
      margin-bottom: 14px;
      border: 1px solid rgba(51,214,255,0.2);
    }

    .card h3 {
      font-size: 19px;
      margin-bottom: 10px;
    }

    .card p {
      color: rgba(255,255,255,0.66);
      line-height: 1.6;
      font-size: 14px;
    }

    /* How it works steps */
    .steps {
      display: grid;
      grid-template-columns: repeat(4, 1fr);
      gap: 20px;
    }

    .step-card {
      padding: 22px;
      border-radius: 22px;
      border: 1px solid rgba(255,255,255,0.08);
      background: rgba(255,255,255,0.03);
      position: relative;
      overflow: hidden;
    }

    .step-num {
      position: absolute;
      top: 16px;
      left: 16px;
      width: 42px;
      height: 28px;
      border-radius: 999px;
      background: rgba(51,214,255,0.16);
      border: 1px solid rgba(51,214,255,0.25);
      color: #33d6ff;
      display: grid;
      place-items: center;
      font-weight: 800;
      font-size: 13px;
    }

    .step-card h3 {
      margin-top: 50px;
      font-size: 18px;
      margin-bottom: 10px;
    }

    .step-card p {
      color: rgba(255,255,255,0.66);
      font-size: 14px;
      line-height: 1.6;
    }

    /* Demo Section */
    .demo-wrap {
      display: grid;
      grid-template-columns: 1.1fr 0.9fr;
      gap: 20px;
      align-items: start;
    }

    .demo-card {
      border-radius: 24px;
      border: 1px solid rgba(255,255,255,0.09);
      background: rgba(255,255,255,0.03);
      padding: 18px;
    }

    .preview-box {
      width: 100%;
      aspect-ratio: 16/9;
      border-radius: 20px;
      background: rgba(255,255,255,0.04);
      border: 1px solid rgba(255,255,255,0.08);
      overflow: hidden;
      display: grid;
      place-items: center;
      position: relative;
    }

    .preview-box img {
      width: 100%;
      height: 100%;
      object-fit: contain;
      display: none;
    }

    /* ‚úÖ ADDED: camera/video preview styling */
    .preview-box video {
      width: 100%;
      height: 100%;
      object-fit: contain;
      display: none;
      background: rgba(0,0,0,0.25);
    }

    .upload-hint {
      text-align: center;
      color: rgba(255,255,255,0.55);
      font-size: 14px;
    }

    .controls {
      display: flex;
      gap: 12px;
      margin-top: 14px;
      flex-wrap: wrap;
    }

    .btn-outline {
      padding: 10px 14px;
      border-radius: 12px;
      background: transparent;
      border: 1px solid rgba(255,255,255,0.14);
      color: white;
      cursor: pointer;
      font-weight: 700;
    }

    .btn-outline:hover {
      border-color: rgba(51,214,255,0.35);
      color: #33d6ff;
    }

    .loader {
      position: absolute;
      inset: 0;
      display: none;
      align-items: center;
      justify-content: center;
      background: rgba(0,0,0,0.55);
      backdrop-filter: blur(4px);
      color: #33d6ff;
      font-weight: 800;
      border-radius: 20px;
    }

    .emotion-list {
      display: grid;
      gap: 14px;
    }

    .emotion-row {
      border: 1px solid rgba(255,255,255,0.08);
      background: rgba(255,255,255,0.03);
      border-radius: 18px;
      padding: 14px;
    }

    .emotion-row-top {
      display: flex;
      justify-content: space-between;
      align-items: center;
      margin-bottom: 10px;
    }

    .emotion-name {
      font-weight: 900;
      font-size: 16px;
    }

    .emotion-val {
      color: #33d6ff;
      font-weight: 900;
    }

    .bar {
      width: 100%;
      height: 10px;
      background: rgba(255,255,255,0.06);
      border-radius: 999px;
      overflow: hidden;
      border: 1px solid rgba(255,255,255,0.07);
    }

    .bar > div {
      height: 100%;
      width: 0%;
      background: linear-gradient(90deg, #33d6ff, #3b82f6);
      border-radius: 999px;
      transition: width 0.4s ease;
    }

    /* Footer */
    footer {
      padding: 40px 22px;
      border-top: 1px solid rgba(255,255,255,0.08);
      background: rgba(5,10,20,0.65);
      backdrop-filter: blur(12px);
    }

    .footer-grid {
      max-width: 1200px;
      margin: auto;
      display: grid;
      grid-template-columns: 1.3fr 1fr 1fr;
      gap: 30px;
    }

    .muted {
      color: rgba(255,255,255,0.65);
      line-height: 1.6;
      font-size: 14px;
    }

    .footer-title {
      font-weight: 900;
      margin-bottom: 10px;
    }

    .footer-links a {
      display: block;
      margin-top: 8px;
      color: rgba(255,255,255,0.65);
      text-decoration: none;
      font-size: 14px;
    }

    .footer-links a:hover {
      color: #33d6ff;
    }

    .copy {
      max-width: 1200px;
      margin: 25px auto 0 auto;
      text-align: center;
      color: rgba(255,255,255,0.5);
      font-size: 13px;
    }

    /* Responsive */
    @media(max-width: 980px) {
      .stats { grid-template-columns: repeat(2, 1fr); }
      .grid3 { grid-template-columns: 1fr; }
      .steps { grid-template-columns: 1fr; }
      .demo-wrap { grid-template-columns: 1fr; }
      nav ul { display: none; }
      .hero h1 { font-size: 38px; }
    }

    /* ===== BETTER BUTTON LAYOUT ===== */
/* ===== CLEAN 2-ROW BUTTON LAYOUT ===== */
.controls {
  display: flex;
  flex-direction: column;
  align-items: center;
  gap: 14px;
  margin-top: 18px;
}

/* Each row of buttons */
.controls .btn-row {
  display: flex;
  justify-content: center;
  gap: 16px;
  flex-wrap: wrap;
}

/* Make buttons consistent size */
.controls button {
  min-width: 170px;
  padding: 12px 16px;
}

    /* ===== ANALYTICS SIZE FIX ===== */
.analytics-row {
  display: grid;
  grid-template-columns: 0.7fr 1.3fr;
  gap: 20px;
  margin-top: 30px;
}

.small-chart {
  max-width: 420px;
  min-height: 360px;
}

.big-chart {
  min-height: 360px;
}

#emotionChart {
  max-width: 260px;
  max-height: 260px;
  margin: auto;
}

#confidenceChart {
  width: 100% !important;
  height: 320px !important;
}
/* ===== PROFESSIONAL ANIMATED CHATBOX ===== */
.chat-container {
  margin-top: 20px;
  border-radius: 18px;
  border: 1px solid rgba(255,255,255,0.12);
  background: rgba(255,255,255,0.05);
  backdrop-filter: blur(6px);
  padding: 14px;
  animation: slideUp 0.5s ease-out;
}

/* Chat slide animation */
@keyframes slideUp {
  from { transform: translateY(20px); opacity: 0; }
  to { transform: translateY(0); opacity: 1; }
}

.chat-header {
  font-weight: 900;
  font-size: 16px;
  color: #33d6ff;
  margin-bottom: 10px;
}

.chat-messages {
  height: 180px;
  overflow-y: auto;
  background: rgba(0,0,0,0.2);
  border-radius: 12px;
  padding: 10px;
  font-size: 14px;
  margin-bottom: 10px;
}

.chat-input-row {
  display: flex;
  gap: 10px;
}

#chatInput {
  flex: 1;
  padding: 10px;
  border-radius: 10px;
  border: none;
  outline: none;
}


  </style>
</head>

<body>
  <div class="bg-dots"></div>

  <!-- NAVBAR -->
  <header>
    <div class="nav">
      <div class="brand">
        <div class="brand-logo"><span>üß†</span></div>
        EmotiSense
      </div>

      <nav>
        <ul>
          <li><a href="#home">Home</a></li>
          <li><a href="#demo">Demo</a></li>
          <li><a href="#features">Features</a></li>
          <li><a href="#how">How It Works</a></li>
          <li><a href="#applications">Applications</a></li>
        </ul>
      </nav>

      <button class="btn-primary" onclick="document.querySelector('#demo').scrollIntoView()">Try Demo</button>
    </div>
  </header>

  <!-- HERO -->
  <section id="home" class="hero">
    <div class="pill">‚ú® AI-Powered Emotion Recognition</div>

    <h1>
      Real-Time <span class="accent">Emotion Detection</span><br/>
      from Facial Expressions
    </h1>

    <p>
      Harness the power of Computer Vision and Deep Learning to understand human emotions through visual cues.
      Detect happiness, sadness, anger, fear, surprise, and neutral expressions in real-time.
    </p>

    <div class="hero-actions">
      <button class="btn-primary" onclick="document.querySelector('#demo').scrollIntoView()">Start Detection ‚Üí</button>
      <button class="btn-secondary" onclick="document.querySelector('#features').scrollIntoView()">‚ñ∂ Learn More</button>
    </div>

    <div class="stats">
      <div class="stat-card">
        <h2>6</h2>
        <p>Emotions</p>
      </div>
      <div class="stat-card">
        <h2>95%+</h2>
        <p>Accuracy</p>
      </div>
      <div class="stat-card">
        <h2>&lt;50ms</h2>
        <p>Latency</p>
      </div>
      <div class="stat-card">
        <h2>Real-Time</h2>
        <p>Processing</p>
      </div>
    </div>
  </section>

  <!-- FEATURES -->
  <section id="features">
    <div class="section-title">
      <h2>Powerful <span>Features</span></h2>
      <p>
        Built with cutting-edge technology stack combining computer vision and deep learning for accurate emotion recognition.
      </p>
    </div>

    <div class="grid3">
      <div class="card">
        <div class="icon-box">üß†</div>
        <h3>Deep Learning CNN</h3>
        <p>Advanced Convolutional Neural Networks trained on facial expressions for accurate emotion classification.</p>
      </div>

      <div class="card">
        <div class="icon-box">‚ö°</div>
        <h3>Real-Time Processing</h3>
        <p>Ultra-low latency inference enabling smooth real-time emotion detection from live streams.</p>
      </div>

      <div class="card">
        <div class="icon-box">üëÅÔ∏è</div>
        <h3>Computer Vision</h3>
        <p>State-of-the-art face detection and preprocessing using OpenCV for robust feature extraction.</p>
      </div>
    </div>

    <div style="height: 22px"></div>

    <div class="grid3">
      <div class="card">
        <div class="icon-box">üõ°Ô∏è</div>
        <h3>Privacy First</h3>
        <p>All processing happens locally. No facial data is stored or transmitted to external servers.</p>
      </div>

      <div class="card">
        <div class="icon-box">‚öôÔ∏è</div>
        <h3>Optimized Model</h3>
        <p>Lightweight architecture optimized for deployment without sacrificing accuracy.</p>
      </div>

      <div class="card">
        <div class="icon-box">üìä</div>
        <h3>Detailed Analytics</h3>
        <p>Comprehensive confidence scores and detailed emotion metrics for each prediction.</p>
      </div>
    </div>
  </section>

  <!-- HOW IT WORKS -->
  <section id="how">
    <div class="section-title">
      <h2>How It <span>Works</span></h2>
      <p>A streamlined pipeline from image capture to emotion classification using deep learning techniques.</p>
    </div>

    <div class="steps">
      <div class="step-card">
        <div class="step-num">01</div>
        <h3>Image Capture</h3>
        <p>Upload a static image to analyze facial expression and detect emotion instantly.</p>
      </div>

      <div class="step-card">
        <div class="step-num">02</div>
        <h3>Face Detection</h3>
        <p>OpenCV isolates face region using Haar cascade classifiers for better accuracy.</p>
      </div>

      <div class="step-card">
        <div class="step-num">03</div>
        <h3>CNN Analysis</h3>
        <p>The processed face is fed to trained CNN model to classify the emotion category.</p>
      </div>

      <div class="step-card">
        <div class="step-num">04</div>
        <h3>Emotion Output</h3>
        <p>Result is shown with confidence score, providing real-time emotion prediction.</p>
      </div>
    </div>
  </section>


    <!-- ================= ANALYTICS ================= -->
<!-- ================= ANALYTICS ================= -->
<section id="analytics">
  <div class="section-title">
    <h2>Detection <span>Analytics</span></h2>
    <p>Real-time emotion detection statistics</p>
  </div>

  <!-- TOP 3 STATS -->
  <div class="grid3">
    <div class="card">
      <h3>Total Detections</h3>
      <h2 id="totalDetections">0</h2>
    </div>

    <div class="card">
      <h3>Average Confidence</h3>
      <h2 id="avgConfidence">0%</h2>
    </div>

    <div class="card">
      <h3>Last Emotion</h3>
      <h2 id="lastEmotion">‚Äî</h2>
    </div>
  </div>

  <!-- CHART ROW (FIXED ALIGNMENT) -->
  <div class="analytics-row">
    <div class="card small-chart">
      <h3>Emotion Distribution</h3>
      <canvas id="emotionChart"></canvas>
    </div>

    <div class="card big-chart">
      <h3>Confidence Distribution</h3>
      <canvas id="confidenceChart"></canvas>
    </div>
  </div>
</section>



    <div class="demo-wrap">
      <!-- LEFT -->
      <div class="demo-card">
        <div class="preview-box" id="previewBox">
          <div class="loader" id="loader">Analyzing...</div>

          <!-- existing image preview -->
          <img id="previewImg" alt="preview" />

          <!-- ‚úÖ ADDED camera preview -->
          <video id="cameraVideo" autoplay muted playsinline></video>

          <!-- ‚úÖ ADDED uploaded video preview -->
          <video id="videoPreview" playsinline></video>

          <div class="upload-hint" id="hintText">
            Click <b>Upload Image</b> to analyze emotion
          </div>
        </div>

  <div class="controls">

  <!-- ROW 1 -->
  <div class="btn-row">
    <input type="file" id="fileInput" hidden accept="image/*"/>
    <button class="btn-primary" id="btnUpload">‚¨Ü Upload Image</button>
    <button class="btn-outline" id="btnPredict" disabled>‚ö° Predict</button>
    <button class="btn-outline" id="btnStartCam">‚ñ∂ Start Camera</button>
    <button class="btn-outline" id="btnStopCam" disabled>‚ñ† Stop Camera</button>
  </div>

  <!-- ROW 2 -->
  <div class="btn-row">
    <input type="file" id="videoInput" hidden accept="video/*"/>
    <button class="btn-primary" id="btnUploadVideo">‚¨Ü Upload Video</button>
    <button class="btn-outline" id="btnDetectVideo" disabled>‚ñ∂ Detect Video</button>
    <button class="btn-outline" id="btnStopVideo" disabled>‚ñ† Stop Video</button>
    <button class="btn-outline" id="btnReset">‚Üª Reset</button>
  </div>

</div>



        <p id="statusText" style="margin-top:12px; color: rgba(255,255,255,0.6); font-size: 13px;">
  Backend URL: http://127.0.0.1:5000/predict
</p>

        <button onclick="testBackend()" class="btn-outline">
  Test Backend
</button>

      </div>

      <!-- RIGHT -->
      <div class="emotion-list" id="emotionList">
        <!-- auto generated -->
      </div>
     <div id="chatBox" class="chat-container" style="display:none;">
  <div class="chat-header">
    ü§ñ AI Emotion Assistant
  </div>

  <div id="chatMessages" class="chat-messages"></div>

  <div class="chat-input-row">
    <input id="chatInput" placeholder="Type your message..." />
    <button class="btn-primary" onclick="sendUserMessage()">Send</button>
  </div>
</div>

  
  </section>

  <!-- APPLICATIONS -->
  <section id="applications">
    <div class="section-title">
      <h2>Applications <span>Areas</span></h2>
      <p>Emotion detection can be applied in multiple real-world domains to enhance human-computer interaction.</p>
    </div>

    <div class="grid3">
      <div class="card">
        <div class="icon-box">üéì</div>
        <h3>E-Learning</h3>
        <p>Detect student engagement & focus during online learning sessions.</p>
      </div>

      <div class="card">
        <div class="icon-box">üßë‚Äçüíº</div>
        <h3>Workplace Wellbeing</h3>
        <p>Monitor stress levels and emotional patterns for better productivity.</p>
      </div>

      <div class="card">
        <div class="icon-box">üè•</div>
        <h3>Healthcare</h3>
        <p>Support mental health analysis and assist emotion-aware therapy tools.</p>
      </div>
    </div>
  </section>

  <!-- FOOTER -->
  <footer>
    <div class="footer-grid">
      <div>
        <div class="brand" style="margin-bottom: 10px;">
          <div class="brand-logo"><span>üß†</span></div>
          EmotiSense
        </div>
        <p class="muted">
          Real-time emotion detection system using computer vision and deep learning.
          A final year project showcasing the power of AI in understanding human emotions.
        </p>
      </div>

      <div class="footer-links">
        <div class="footer-title">Quick Links</div>
        <a href="#home">Home</a>
        <a href="#demo">Demo</a>
        <a href="#features">Features</a>
        <a href="#how">How It Works</a>
        <a href="#applications">Applications</a>
      </div>

      <div>
        <div class="footer-title">Project Info</div>
        <p class="muted"><b>Type:</b> Final Year Project</p>
        <p class="muted"><b>Domain:</b> AI/ML & Computer Vision</p>
        <p class="muted"><b>Tech:</b> TensorFlow, OpenCV, Python, HTML</p>
        <p class="muted"><b>Year:</b> 2024-2025</p>
      </div>
    </div>

    <div class="copy">¬© 2024 EmotiSense. All rights reserved.</div>
  </footer>

  <script>
 const BACKEND_URL = "http://127.0.0.1:5000/predict";



    const fileInput = document.getElementById("fileInput");
    const btnUpload = document.getElementById("btnUpload");
    const btnPredict = document.getElementById("btnPredict");
    const btnReset = document.getElementById("btnReset");

    const previewImg = document.getElementById("previewImg");
    const hintText = document.getElementById("hintText");
    const loader = document.getElementById("loader");
    const statusText = document.getElementById("statusText");

    const emotionList = document.getElementById("emotionList");

    // ‚úÖ ADDED DOM for camera/video
    const cameraVideo = document.getElementById("cameraVideo");
    const videoPreview = document.getElementById("videoPreview");

    const btnStartCam = document.getElementById("btnStartCam");
    const btnStopCam = document.getElementById("btnStopCam");

    const videoInput = document.getElementById("videoInput");
    const btnUploadVideo = document.getElementById("btnUploadVideo");
    const btnDetectVideo = document.getElementById("btnDetectVideo");
    const btnStopVideo = document.getElementById("btnStopVideo");

    let currentFile = null;
    let cameraStream = null;
    let camInterval = null;
    let vidInterval = null;

    // UI Emotions (match backend labels)
   const emotions = ["Angry", "Fear", "Happy", "Neutral", "Sad", "Surprise"];


    function createEmotionCards() {
      emotionList.innerHTML = "";
      emotions.forEach(e => {
        const div = document.createElement("div");
        div.className = "emotion-row";
        div.innerHTML = `
          <div class="emotion-row-top">
            <div class="emotion-name">${e}</div>
            <div class="emotion-val" id="val-${e}">0%</div>
          </div>
          <div class="bar"><div id="bar-${e}"></div></div>
        `;
        emotionList.appendChild(div);
      });
    }
function resetBars() {
  emotions.forEach(e => {
    document.getElementById(`val-${e}`).textContent = "0%";
    document.getElementById(`bar-${e}`).style.width = "0%";
  });

  // ‚úÖ KEEP CHATBOX VISIBLE
  document.getElementById("chatBox").style.display = "block";
}


    function hideAllPreview() {
      previewImg.style.display = "none";
      cameraVideo.style.display = "none";
      videoPreview.style.display = "none";
      hintText.style.display = "block";
    }

    function stopCameraDetection() {
      if (camInterval) clearInterval(camInterval);
      camInterval = null;

      if (cameraStream) {
        cameraStream.getTracks().forEach(t => t.stop());
        cameraStream = null;
      }

      cameraVideo.srcObject = null;

      btnStopCam.disabled = true;
      btnStartCam.disabled = false;
    }

    function stopVideoDetection() {
      if (vidInterval) clearInterval(vidInterval);
      vidInterval = null;

      videoPreview.pause();

      btnStopVideo.disabled = true;
      btnDetectVideo.disabled = false;
    }

    createEmotionCards();
    resetBars();

    // ‚úÖ helper: send blob to backend
    async function sendBlobToBackend(blob) {
      const fd = new FormData();
      fd.append("image", blob, "frame.jpg");

      const res = await fetch(BACKEND_URL, {
        method: "POST",
        body: fd
      });

      if (!res.ok) throw new Error("Backend error: " + res.status);
      return await res.json();
    }


  async function saveFrame(blob, emotionName, confidenceValue) {
  const fd = new FormData();
  fd.append("image", blob, "frame.jpg");

  // ‚úÖ send emotion + confidence to backend
  fd.append("emotion", emotionName);
  fd.append("confidence", confidenceValue);

  const res = await fetch("http://127.0.0.1:5000/capture", {
    method: "POST",
    body: fd
  });

  if (!res.ok) {
    console.log("‚ùå Save frame failed", res.status);
    return;
  }

  const data = await res.json();
  console.log("‚úÖ Saved:", data.file);
}


    // ‚úÖ helper: capture frame from video element
   async function captureFrame(videoEl) {
  const canvas = document.createElement("canvas");

  // ‚úÖ KEEP ORIGINAL CAMERA SIZE
  canvas.width = videoEl.videoWidth;
  canvas.height = videoEl.videoHeight;

  const ctx = canvas.getContext("2d");
  ctx.drawImage(videoEl, 0, 0, canvas.width, canvas.height);

  return await new Promise(resolve => {
    canvas.toBlob(resolve, "image/jpeg", 0.9);
  });
}


    // ---------------- IMAGE (your existing logic, unchanged) ----------------
    btnUpload.addEventListener("click", () => fileInput.click());

    fileInput.addEventListener("change", () => {
      stopCameraDetection();
      stopVideoDetection();

      const file = fileInput.files?.[0];
      if (!file) return;

      currentFile = file;
      const url = URL.createObjectURL(file);

      hideAllPreview();
      previewImg.src = url;
      previewImg.style.display = "block";
      hintText.style.display = "none";

      btnPredict.disabled = false;
      statusText.textContent = "Image loaded ‚úÖ Now click Predict.";
      resetBars();
    });

    btnReset.addEventListener("click", () => {
      stopCameraDetection();
      stopVideoDetection();

      currentFile = null;
      fileInput.value = "";
      videoInput.value = "";

      previewImg.src = "";
      videoPreview.src = "";

      previewImg.style.display = "none";
      cameraVideo.style.display = "none";
      videoPreview.style.display = "none";

      hintText.style.display = "block";
      btnPredict.disabled = true;
      loader.style.display = "none";

      btnDetectVideo.disabled = true;
      btnStopVideo.disabled = true;

      statusText.textContent = "Reset done ‚úÖ Upload again.";
      resetBars();
      document.getElementById("chatBox").style.display = "none";

    });

    btnPredict.addEventListener("click", async () => {
      if (!currentFile) {
        alert("Upload an image first!");
        return;
      }

      try {
        loader.style.display = "flex";
        statusText.textContent = "Sending to backend...";

        const fd = new FormData();
        fd.append("image", currentFile);

        const res = await fetch(BACKEND_URL, {
          method: "POST",
          body: fd
        });

        if (!res.ok) {
          throw new Error("Backend error: " + res.status);
        }

        const data = await res.json();

        resetBars();

        if (!data.face_detected) {
          statusText.textContent = "No face detected ‚ùå Try another image.";
          loader.style.display = "none";
          return;
        }

        const emotion = data.emotion || "Neutral";
        const conf = Math.round(data.confidence || 0);
        updateAnalytics(emotion, conf);
        showChat(emotion);


        document.getElementById(`val-${emotion}`).textContent = conf + "%";
        document.getElementById(`bar-${emotion}`).style.width = conf + "%";

        statusText.textContent = `‚úÖ Emotion: ${emotion} | Confidence: ${conf}%`;
        loader.style.display = "none";

      } catch (err) {
        console.error(err);
        loader.style.display = "none";
        statusText.textContent = "Backend not reachable ‚ùå Check python app.py is running.";
        alert("Backend error. Make sure Flask server is running on port 5000!");
      }
    });

    // ---------------- ‚úÖ CAMERA LIVE DETECTION (ADDED) ----------------
    btnStartCam.addEventListener("click", async () => {
      try {
        stopVideoDetection(); // avoid conflicts

        loader.style.display = "flex";
        statusText.textContent = "Requesting camera...";

        cameraStream = await navigator.mediaDevices.getUserMedia({
          video: { width: 1280, height: 720 },
          audio: false
        });

        hideAllPreview();
        cameraVideo.style.display = "block";
        hintText.style.display = "none";

        cameraVideo.srcObject = cameraStream;
      await new Promise(r => cameraVideo.onloadedmetadata = r);

        btnStartCam.disabled = true;
        btnStopCam.disabled = false;

        loader.style.display = "none";
        statusText.textContent = "Camera started ‚úÖ Detecting every 1.5 sec";

    camInterval = setInterval(async () => {
  try {
    const blob = await captureFrame(cameraVideo);
    const data = await sendBlobToBackend(blob);
    console.log("CAM DATA:", data);

    resetBars();

    if (!data.face_detected) {
      statusText.textContent = "No face detected ‚ùå (Camera)";
      return;
    }

    const emotion = (data.emotion || "Neutral").trim();

    const conf = Math.round(data.confidence || 0);
    updateAnalytics(emotion, conf);

    showChat(emotion);

    // ‚úÖ SAVE camera frame with emotion name
    await saveFrame(blob, emotion, conf);

    document.getElementById(`val-${emotion}`).textContent = conf + "%";
    document.getElementById(`bar-${emotion}`).style.width = conf + "%";
    statusText.textContent = `‚úÖ Camera: ${emotion} | ${conf}%`;

  } catch (e) {
    console.log("camera detect error", e);
  }
}, 5000);


      } catch (err) {
        console.error(err);
        loader.style.display = "none";
        statusText.textContent = "Camera denied ‚ùå Allow camera permission.";
      }
    });

    btnStopCam.addEventListener("click", () => {
      stopCameraDetection();
      resetBars();
      hideAllPreview();
      statusText.textContent = "Camera stopped ‚úÖ";
    });

    // ---------------- ‚úÖ VIDEO UPLOAD DETECTION (ADDED) ----------------
    btnUploadVideo.addEventListener("click", () => {
      stopCameraDetection(); // avoid conflicts
      videoInput.click();
    });

    videoInput.addEventListener("change", () => {
      const file = videoInput.files?.[0];
      if (!file) return;

      const url = URL.createObjectURL(file);

      hideAllPreview();
      videoPreview.src = url;
      videoPreview.style.display = "block";
      hintText.style.display = "none";

      btnDetectVideo.disabled = false;
      btnStopVideo.disabled = true;

      statusText.textContent = "Video loaded ‚úÖ Click Detect Video.";
      resetBars();
    });

    btnDetectVideo.addEventListener("click", async () => {
      try {
        if (!videoPreview.src) {
          alert("Upload a video first!");
          return;
        }

        btnDetectVideo.disabled = true;
        btnStopVideo.disabled = false;

        statusText.textContent = "Starting video detection...";
        await videoPreview.play();

        statusText.textContent = "Video running ‚úÖ Detecting every 2 sec";

        if (vidInterval) clearInterval(vidInterval);

vidInterval = setInterval(async () => {
  try {
    if (videoPreview.paused || videoPreview.ended) return;
    if (!videoPreview.videoWidth || !videoPreview.videoHeight) return;

    const blob = await captureFrame(videoPreview);
    const data = await sendBlobToBackend(blob);

    if (!data.face_detected) {
      statusText.textContent = "No face detected ‚ùå (Video)";
      return;
    }

    const emotion = (data.emotion || "Neutral").trim();
    const conf = Math.round(data.confidence || 0);
    updateAnalytics(emotion, conf);
    showChat(emotion);

    // ‚úÖ SAVE video frame
    const saved = await saveFrame(blob, emotion, conf);
    console.log("‚úÖ VIDEO FRAME SAVED:", saved);

    resetBars();

    document.getElementById(`val-${emotion}`).textContent = conf + "%";
    document.getElementById(`bar-${emotion}`).style.width = conf + "%";
    statusText.textContent = `‚úÖ Video: ${emotion} | ${conf}%`;

  } catch (e) {
    console.log("video detect error", e);
  }
}, 2000);



      } catch (err) {
        console.error(err);
        statusText.textContent = "Video detection failed ‚ùå";
        btnDetectVideo.disabled = false;
        btnStopVideo.disabled = true;
      }
    });

    btnStopVideo.addEventListener("click", () => {
      stopVideoDetection();
      resetBars();
      statusText.textContent = "Video detection stopped ‚úÖ";
    });
    // ---------------- AI CHAT LOGIC ----------------
let currentEmotionForChat = "Neutral";

const emotionReplies = {
  Sad: [
    "I can see you're feeling sad. I'm here with you. What happened?",
    "That sounds really heavy. Do you want to talk about what‚Äôs on your mind?",
    "Take a slow breath ‚Äî I'm listening. Tell me more."
  ],

  Happy: [
    "You look genuinely happy! What made your day good?",
    "Love that energy üòÑ ‚Äî want to share your win?",
    "Your mood is bright! What are you celebrating?"
  ],

  Angry: [
    "I sense some anger. Let‚Äôs pause for a second ‚Äî what triggered this?",
    "It‚Äôs okay to feel angry. What happened?",
    "Breathe with me once‚Ä¶ now tell me what‚Äôs bothering you."
  ],

  Fear: [
    "You‚Äôre safe right now. What are you worried about?",
    "I‚Äôm here with you ‚Äî what feels scary?",
    "Let‚Äôs break this down together. What happened?"
  ],

  Surprise: [
    "That reaction looks unexpected! What just happened?",
    "Whoa ‚Äî good surprise or bad surprise?",
    "Tell me the story behind that moment!"
  ],

  Neutral: [
    "How are you feeling right now?",
    "What‚Äôs on your mind?",
    "Want to talk about your day?"
  ]
};


function showChat(emotion) {
  document.getElementById("chatBox").style.display = "block";

  currentEmotionForChat = emotion;
  const chatBox = document.getElementById("chatBox");
  chatBox.style.display = "block";   // üëà stays open

  const chat = document.getElementById("chatMessages");

  if (chat.innerHTML.trim() === "") {   // only first time
    const starter =
      emotionReplies[emotion]?.[0] ||
      "I'm here to talk üòä";
    addAIMessage(starter);
  }
}



function addAIMessage(msg) {
  const chat = document.getElementById("chatMessages");
  chat.innerHTML += `<div style="margin-bottom:8px;"><b>AI:</b> ${msg}</div>`;
  chat.scrollTop = chat.scrollHeight;

  // üîä VOICE ASSISTANT
  speak(msg);
}

async function sendUserMessage() {
  const input = document.getElementById("chatInput");
  const text = input.value.trim();
  if (!text) return;

  const chat = document.getElementById("chatMessages");
  chat.innerHTML += `<div style="margin-bottom:8px;"><b>You:</b> ${text}</div>`;
  input.value = "";

  // Send to real GPT backend
  const res = await fetch("http://127.0.0.1:5000/chat", {
    method: "POST",
    headers: { "Content-Type": "application/json" },
    body: JSON.stringify({
      message: text,
      emotion: currentEmotionForChat
    })
  });

  const data = await res.json();
  addAIMessage(data.reply);
}

// ================= ANALYTICS LOGIC =================
let detectionCount = 0;
let confidenceSum = 0;

const emotionStats = {
  Happy: 0,
  Sad: 0,
  Angry: 0,
  Fear: 0,
  Surprise: 0,
  Neutral: 0
};

const confidenceBuckets = {
  "50-60": 0,
  "60-70": 0,
  "70-80": 0,
  "80-90": 0,
  "90-100": 0
};

// Emotion Donut Chart
const emotionChart = new Chart(document.getElementById("emotionChart"), {
  type: "doughnut",
  data: {
    labels: Object.keys(emotionStats),
    datasets: [{
      data: Object.values(emotionStats),
      backgroundColor: [
        "#22c55e", "#3b82f6", "#ef4444",
        "#a855f7", "#facc15", "#94a3b8"
      ]
    }]
  }
});

// Confidence Bar Chart
const confidenceChart = new Chart(document.getElementById("confidenceChart"), {
  type: "bar",
  data: {
    labels: Object.keys(confidenceBuckets),
    datasets: [{
      label: "Detections",
      data: Object.values(confidenceBuckets),
      backgroundColor: "#38bdf8"
    }]
  },
  options: {
    scales: { y: { beginAtZero: true } }
  }
});

// UPDATE ANALYTICS
function updateAnalytics(emotion, confidence) {
  detectionCount++;
  confidenceSum += confidence;

  emotionStats[emotion]++;
  document.getElementById("totalDetections").textContent = detectionCount;
  document.getElementById("avgConfidence").textContent =
    Math.round(confidenceSum / detectionCount) + "%";
  document.getElementById("lastEmotion").textContent = emotion;

  if (confidence >= 90) confidenceBuckets["90-100"]++;
  else if (confidence >= 80) confidenceBuckets["80-90"]++;
  else if (confidence >= 70) confidenceBuckets["70-80"]++;
  else if (confidence >= 60) confidenceBuckets["60-70"]++;
  else confidenceBuckets["50-60"]++;

  emotionChart.data.datasets[0].data = Object.values(emotionStats);
  confidenceChart.data.datasets[0].data = Object.values(confidenceBuckets);

  emotionChart.update();
  confidenceChart.update();
}
function speak(text) {
  const utterance = new SpeechSynthesisUtterance(text);
  utterance.rate = 1;      // speed
  utterance.pitch = 1;     // tone
  utterance.volume = 1;    // loudness
  window.speechSynthesis.speak(utterance);
}
async function testBackend() {
  try {
    const res = await fetch("http://127.0.0.1:5000/");
    const text = await res.text();
    alert("Backend says: " + text);
  } catch (e) {
    alert("Backend NOT reachable!");
  }
}



  </script>
</body>
</html>  